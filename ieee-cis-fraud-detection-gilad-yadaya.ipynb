{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc,os,sys\n",
    "import re\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #else:\n",
    "            #df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB --> {:.2f} MB (Decreased by {:.1f}%)'.format(\n",
    "        start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_id = pd.read_csv('../input/train_identity.csv')\n",
    "train_trn = pd.read_csv('../input/train_transaction.csv')\n",
    "test_id = pd.read_csv('../input/test_identity.csv')\n",
    "test_trn = pd.read_csv('../input/test_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = reduce_mem_usage(train_id)\n",
    "train_trn = reduce_mem_usage(train_trn)\n",
    "test_id = reduce_mem_usage(test_id)\n",
    "test_trn = reduce_mem_usage(test_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_id.shape, test_id.shape)\n",
    "print(train_trn.shape, test_trn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### what's target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in train_trn.columns if c not in test_trn.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = train_trn['isFraud'].value_counts(normalize=True).to_frame()\n",
    "fc.plot.bar()\n",
    "fc.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud transaction rate by day, and week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2, 1, figsize=(16,8))\n",
    "\n",
    "train_trn['_seq_day'] = train_trn['TransactionDT'] // (24*60*60)\n",
    "train_trn['_seq_week'] = train_trn['_seq_day'] // 7\n",
    "train_trn.groupby('_seq_day')['isFraud'].mean().to_frame().plot.line(ax=ax[0])\n",
    "train_trn.groupby('_seq_week')['isFraud'].mean().to_frame().plot.line(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud transaction rate by weekday, hour, month-day, and year-month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "START_DATE = '2017-11-30'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "train_trn['Date'] = train_trn['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "train_trn['_ymd'] = train_trn['Date'].dt.year.astype(str) + '-' + train_trn['Date'].dt.month.astype(str) + '-' + train_trn['Date'].dt.day.astype(str)\n",
    "train_trn['_year_month'] = train_trn['Date'].dt.year.astype(str) + '-' + train_trn['Date'].dt.month.astype(str)\n",
    "train_trn['_weekday'] = train_trn['Date'].dt.dayofweek\n",
    "train_trn['_hour'] = train_trn['Date'].dt.hour\n",
    "train_trn['_day'] = train_trn['Date'].dt.day\n",
    "\n",
    "fig,ax = plt.subplots(4, 1, figsize=(16,12))\n",
    "\n",
    "train_trn.groupby('_weekday')['isFraud'].mean().to_frame().plot.bar(ax=ax[0])\n",
    "train_trn.groupby('_hour')['isFraud'].mean().to_frame().plot.bar(ax=ax[1])\n",
    "train_trn.groupby('_day')['isFraud'].mean().to_frame().plot.bar(ax=ax[2])\n",
    "train_trn.groupby('_year_month')['isFraud'].mean().to_frame().plot.bar(ax=ax[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud transaction rate by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_trn.groupby(['_ymd'])['isFraud'].agg(['count','mean','sum'])\n",
    "df.sort_values(by='mean',ascending=False)[:10].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='count',ascending=False)[:10].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction-count X fraud-rate\n",
    "plt.scatter(df['count'], df['mean'], s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction-count X fraud-count\n",
    "plt.scatter(df['count'], df['sum'], s=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud transaction rate by weekday-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['_weekday_hour'] = train_trn['_weekday'].astype(str) + '_' + train_trn['_hour'].astype(str)\n",
    "train_trn.groupby('_weekday_hour')['isFraud'].mean().to_frame().plot.line(figsize=(16,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud rate by weekday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_trn.groupby('_weekday')['isFraud'].mean().to_frame()\n",
    "df.sort_values(by='isFraud', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud rate by hour "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_trn.groupby('_hour')['isFraud'].mean().to_frame()\n",
    "df.sort_values(by='isFraud', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud rate by weekday-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_trn.groupby('_weekday_hour')['isFraud'].mean().to_frame()\n",
    "df.sort_values(by='isFraud', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fraud rate by amount-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['_amount_qcut10'] = pd.qcut(train_trn['TransactionAmt'],10)\n",
    "df = train_trn.groupby('_amount_qcut10')['isFraud'].mean().to_frame()\n",
    "df.sort_values(by='isFraud', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransactionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all transactions have corresponding identity information.\n",
    "#len([c for c in train_trn['TransactionID'] if c not in train_id['TransactionID'].values]) #446307\n",
    "\n",
    "# Not all fraud transactions have corresponding identity information.\n",
    "fraud_id = train_trn[train_trn['isFraud'] == 1]['TransactionID']\n",
    "fraud_id_in_trn = [i for i in fraud_id if i in train_id['TransactionID'].values]\n",
    "print(f'fraud data count:{len(fraud_id)}, and in trn:{len(fraud_id_in_trn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity data\n",
    "\n",
    "Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions. They're collected by Vesta’s fraud protection system and digital security partners. (The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n",
    "\n",
    "Categorical Features:\n",
    "\n",
    "- DeviceType\n",
    "- DeviceInfo\n",
    "- id12 - id38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_trn = pd.merge(train_id, train_trn[['isFraud','TransactionAmt','TransactionID']])\n",
    "train_id_f0 = train_id_trn[train_id_trn['isFraud'] == 0]\n",
    "train_id_f1 = train_id_trn[train_id_trn['isFraud'] == 1]\n",
    "print(train_id_f0.shape, train_id_f1.shape)\n",
    "\n",
    "def plotHistByFraud(col, bins=20, figsize=(8,3)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.hist([train_id_f0[col], train_id_f1[col]], bins=bins, density=True, color=['royalblue', 'orange'])\n",
    "        \n",
    "def plotCategoryRateBar(col, topN=np.nan, figsize=(8,3)):\n",
    "    a, b = train_id_f0, train_id_f1\n",
    "    if topN == topN: # isNotNan\n",
    "        vals = b[col].value_counts(normalize=True).to_frame().iloc[:topN,0]\n",
    "        subA = a.loc[a[col].isin(vals.index.values), col]\n",
    "        df = pd.DataFrame({'normal':subA.value_counts(normalize=True), 'fraud':vals})\n",
    "    else:\n",
    "        df = pd.DataFrame({'normal':a[col].value_counts(normalize=True), 'fraud':b[col].value_counts(normalize=True)})\n",
    "    df.sort_values('fraud', ascending=False).plot.bar(figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id_01 - id_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHistByFraud('id_01')\n",
    "plotHistByFraud('id_02')\n",
    "plotHistByFraud('id_07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numid_cols = [f'id_{str(i).zfill(2)}' for i in range(1,12)]\n",
    "train_id_trn[numid_cols].isna().sum().to_frame().T / len(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(train_id_trn[['isFraud','TransactionAmt']+numid_cols].corr(), annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_f1[['isFraud'] + numid_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_f0[['isFraud'] + numid_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id_12 - id_38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_15')\n",
    "plotCategoryRateBar('id_16')\n",
    "plotCategoryRateBar('id_17',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_19', 20)\n",
    "plotHistByFraud('id_19')\n",
    "print('unique count:', train_id['id_19'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_20', 20)\n",
    "plotHistByFraud('id_20')\n",
    "print('unique count:', train_id['id_20'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_26', 15)\n",
    "plotCategoryRateBar('id_28')\n",
    "plotCategoryRateBar('id_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_31', 20)\n",
    "\n",
    "train_id_f0['_id_31_ua'] = train_id_f0['id_31'].apply(lambda x: x.split()[0] if x == x else 'unknown')\n",
    "train_id_f1['_id_31_ua'] = train_id_f1['id_31'].apply(lambda x: x.split()[0] if x == x else 'unknown')\n",
    "plotCategoryRateBar('_id_31_ua', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('id_32')\n",
    "plotCategoryRateBar('id_33',15)\n",
    "plotCategoryRateBar('id_34')\n",
    "plotCategoryRateBar('id_35')\n",
    "plotCategoryRateBar('id_38')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeviceType, DeviceInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCategoryRateBar('DeviceType')\n",
    "plotCategoryRateBar('DeviceInfo',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction data\n",
    "\n",
    "- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "- TransactionAMT: transaction payment amount in USD\n",
    "- ProductCD: product code, the product for each transaction\n",
    "- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "- addr: address\n",
    "- dist: distance\n",
    "- P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "- D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "- M1-M9: match, such as names on card and address, etc.\n",
    "- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccols = [f'C{i}' for i in range(1,15)]\n",
    "dcols = [f'D{i}' for i in range(1,16)]\n",
    "mcols = [f'M{i}' for i in range(1,10)]\n",
    "vcols = [f'V{i}' for i in range(1,340)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn_f0 = train_trn[train_trn['isFraud'] == 0]\n",
    "train_trn_f1 = train_trn[train_trn['isFraud'] == 1]\n",
    "print(train_trn_f0.shape, train_trn_f1.shape)\n",
    "\n",
    "def plotTrnHistByFraud(col, bins=20, figsize=(8,3)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.hist([train_trn_f0[col], train_trn_f1[col]], bins=bins, density=True, color=['royalblue', 'orange'])\n",
    "\n",
    "def plotTrnLogHistByFraud(col, bins=20, figsize=(8,3)):\n",
    "    with np.errstate(invalid='ignore'):\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.hist([np.log1p(train_trn_f0[col]), np.log1p(train_trn_f1[col])], bins=bins, density=True, color=['royalblue', 'orange'])\n",
    "        \n",
    "def plotTrnCategoryRateBar(col, topN=np.nan, figsize=(8,3)):\n",
    "    a, b = train_trn_f0, train_trn_f1\n",
    "    if topN == topN: # isNotNan\n",
    "        vals = b[col].value_counts(normalize=True).to_frame().iloc[:topN,0]\n",
    "        subA = a.loc[a[col].isin(vals.index.values), col]\n",
    "        df = pd.DataFrame({'normal':subA.value_counts(normalize=True), 'fraud':vals})\n",
    "    else:\n",
    "        df = pd.DataFrame({'normal':a[col].value_counts(normalize=True), 'fraud':b[col].value_counts(normalize=True)})\n",
    "    df.sort_values('fraud', ascending=False).plot.bar(figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransactionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#START_DATE = '2017-11-30'\n",
    "START_DATE = '2017-12-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "\n",
    "train_date = train_trn['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "test_date = test_trn['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "\n",
    "print('train date:', train_date.min(), '-', train_date.max())\n",
    "print('test  date:', test_date.min(), '-', test_date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "train_trn['TransactionDT'].hist(bins=20)\n",
    "test_trn['TransactionDT'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendLagDT(df):\n",
    "    df = df.assign(_date_lag = df['TransactionDT'] - df.groupby(['card1','card2'])['TransactionDT'].shift(1))\n",
    "    return df\n",
    "\n",
    "train_trn = appendLagDT(train_trn)\n",
    "train_trn_f0 = train_trn[train_trn['isFraud'] == 0]\n",
    "train_trn_f1 = train_trn[train_trn['isFraud'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_trn_f0['_date_lag'].describe(), \n",
    "           train_trn_f1['_date_lag'].describe()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnLogHistByFraud('_date_lag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TransactionAmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnHistByFraud('TransactionAmt')\n",
    "plotTrnLogHistByFraud('TransactionAmt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amt_desc = pd.concat([train_trn_f0['TransactionAmt'].describe(), train_trn_f1['TransactionAmt'].describe()], axis=1)\n",
    "amt_desc.columns = ['normal','fraud']\n",
    "amt_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendLagAmt(df):\n",
    "    df = df.assign(_amt_lag = df['TransactionAmt'] - df.groupby(['card1','card2'])['TransactionAmt'].shift(1))\n",
    "    df['_amt_lag_sig'] = df['_amt_lag'].apply(lambda x: '0' if np.isnan(x) else '+' if x >=0 else '-')\n",
    "    return df\n",
    "\n",
    "train_trn = appendLagAmt(train_trn)\n",
    "train_trn_f0 = train_trn[train_trn['isFraud'] == 0]\n",
    "train_trn_f1 = train_trn[train_trn['isFraud'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnHistByFraud('_amt_lag')\n",
    "plotTrnCategoryRateBar('_amt_lag_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProductCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('ProductCD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ProductCD','addr1','addr2','dist1','dist2']\n",
    "train_trn[cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['addr1','addr2','dist1','dist2']\n",
    "for f in cols:\n",
    "    train_trn[f + '_isna'] = train_trn[f].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train_trn['ProductCD'], train_trn['addr1_isna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train_trn['ProductCD'], train_trn['dist1_isna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(train_trn['ProductCD'], train_trn['dist2_isna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[(train_trn['dist1_isna'] == False) & (train_trn['dist2_isna'] == False)][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn = pd.concat([train_trn, pd.get_dummies(train_trn[['ProductCD']])], axis=1)\n",
    "train_trn.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ProductCD_W','ProductCD_C','ProductCD_H','ProductCD_R','ProductCD_S','dist1_isna','dist2_isna','addr1_isna','addr2_isna']\n",
    "train_trn[cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['_amount_max_ProductCD'] = train_trn.groupby(['ProductCD'])['TransactionAmt'].transform('max')\n",
    "train_trn[['ProductCD','_amount_max_ProductCD']].drop_duplicates().sort_values(by='_amount_max_ProductCD', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### card1 - card6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [f'card{n}' for n in range(1,7)]\n",
    "train_trn[cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[train_trn['card4']=='visa']['card1'].hist(bins=50)\n",
    "train_trn[train_trn['card4']=='mastercard']['card1'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[train_trn['card4']=='visa']['card2'].hist(bins=50)\n",
    "train_trn[train_trn['card4']=='mastercard']['card2'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('card1', 15)\n",
    "plotTrnHistByFraud('card1', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('card2', 15)\n",
    "plotTrnHistByFraud('card2', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn_f0['_card1_card2'] = train_trn_f0['card1'].astype(str) + '_' + train_trn_f0['card2'].astype(str)\n",
    "train_trn_f1['_card1_card2'] = train_trn_f1['card1'].astype(str) + '_' + train_trn_f1['card2'].astype(str)\n",
    "\n",
    "plotTrnCategoryRateBar('_card1_card2', 50, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('card3', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('card4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('card5', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('card6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_trn))\n",
    "print(train_trn['card1'].nunique(), train_trn['card2'].nunique(), train_trn['card3'].nunique(), train_trn['card5'].nunique())\n",
    "\n",
    "train_trn['card_n'] = (train_trn['card1'].astype(str) + '_' + train_trn['card2'].astype(str) \\\n",
    "       + '_' + train_trn['card3'].astype(str) + '_' + train_trn['card5'].astype(str))\n",
    "print('unique cards:', train_trn['card_n'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = train_trn['card_n'].value_counts()\n",
    "vc[vc > 3000].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn.groupby(['card_n'])['isFraud'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### addr1, addr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['addr1'].nunique(), train_trn['addr2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('addr1', 20)\n",
    "plotTrnHistByFraud('addr1', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['addr1'].value_counts(dropna=False).to_frame().iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('addr2', 10)\n",
    "print('addr2 nunique:', train_trn['addr2'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['addr2'].value_counts(dropna=False).to_frame().iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dist1, dist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('dist1', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('dist2', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn_f0['dist3'] = np.where(train_trn_f0['dist1'].isna(), train_trn_f0['dist2'], train_trn_f0['dist1'])\n",
    "train_trn_f1['dist3'] = np.where(train_trn_f1['dist1'].isna(), train_trn_f1['dist2'], train_trn_f1['dist1'])\n",
    "\n",
    "plotTrnCategoryRateBar('dist3', 20)\n",
    "plotTrnLogHistByFraud('dist3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P_emaildomain, R_emaildomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('P_emaildomain',10)\n",
    "plotTrnCategoryRateBar('R_emaildomain',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['P_emaildomain'].fillna('unknown',inplace=True)\n",
    "train_trn['R_emaildomain'].fillna('unknown',inplace=True)\n",
    "\n",
    "inf = pd.DataFrame([], columns=['P_emaildomain','R_emaildomain','Count','isFraud'])\n",
    "for n in (train_trn['P_emaildomain'] + ' ' + train_trn['R_emaildomain']).unique():\n",
    "    p, r = n.split()[0], n.split()[1]\n",
    "    df = train_trn[(train_trn['P_emaildomain'] == p) & (train_trn['R_emaildomain'] == r)]\n",
    "    inf = inf.append(pd.DataFrame([p, r, len(df), df['isFraud'].mean()], index=inf.columns).T)\n",
    "\n",
    "inf.sort_values(by='isFraud', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn_f1['P_emaildomain_prefix'] = train_trn_f1['P_emaildomain'].fillna('unknown').apply(lambda x: x.split('.')[0])\n",
    "pd.crosstab(train_trn_f1['P_emaildomain_prefix'], train_trn_f1['ProductCD']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn['P_emaildomain_prefix'] = train_trn['P_emaildomain'].apply(lambda x: x.split('.')[0])\n",
    "ct = pd.crosstab(train_trn['P_emaildomain_prefix'], train_trn['ProductCD'])\n",
    "ct = ct.sort_values(by='W')[-15:]\n",
    "ct.plot.barh(stacked=True, figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C1 - C14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,15):\n",
    "    plotTrnCategoryRateBar(f'C{i}',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[ccols].describe().loc[['count','mean','std','min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "corr = train_trn[['isFraud'] + ccols].corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cx & card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TransactionDT','TransactionAmt','isFraud'] + ccols\n",
    "train_trn[train_trn['card1'] == 9500][cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TransactionDT','TransactionAmt','isFraud'] + ccols\n",
    "train_trn[train_trn['card1'] == 4774][cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[train_trn['card1'] == 14770][cols].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D1-D15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,16):\n",
    "    plotTrnCategoryRateBar(f'D{i}',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[dcols].describe().loc[['count','mean','std','min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.scatter(train_trn_f0['TransactionDT'], train_trn_f0['D1'], s=2)\n",
    "plt.scatter(train_trn_f1['TransactionDT'], train_trn_f1['D1'], s=2, c='r')\n",
    "plt.scatter(test_trn['TransactionDT'], test_trn['D1'], s=2, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# ref. https://www.kaggle.com/kyakovlev/ieee-columns-scaling\n",
    "plt.scatter(train_trn_f0['TransactionDT'], train_trn_f0['D15'], s=2)\n",
    "plt.scatter(train_trn_f1['TransactionDT'], train_trn_f1['D15'], s=2, c='r')\n",
    "plt.scatter(test_trn['TransactionDT'], test_trn['D15'], s=2, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "corr = train_trn[['isFraud'] + dcols].corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "train_trn.loc[train_trn['isFraud']==0, dcols].isnull().sum(axis=1).to_frame().hist(ax=ax[0], bins=20)\n",
    "train_trn.loc[train_trn['isFraud']==1, dcols].isnull().sum(axis=1).to_frame().hist(ax=ax[1], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dx & card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TransactionDT','TransactionAmt','isFraud'] + dcols\n",
    "train_trn[train_trn['card1'] == 9500][cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['TransactionDT','TransactionAmt','isFraud'] + dcols\n",
    "train_trn[train_trn['card1'] == 4774][cols].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[train_trn['card1'] == 14770][cols].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M1 - M9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('M1')\n",
    "plotTrnCategoryRateBar('M2')\n",
    "plotTrnCategoryRateBar('M3')\n",
    "plotTrnCategoryRateBar('M4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTrnCategoryRateBar('M5')\n",
    "plotTrnCategoryRateBar('M6')\n",
    "plotTrnCategoryRateBar('M7')\n",
    "plotTrnCategoryRateBar('M8')\n",
    "plotTrnCategoryRateBar('M9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['V1','V14','V41','V65','V88','V107','V305']:\n",
    "    plotTrnCategoryRateBar(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsum0 = train_trn_f0[vcols].sum(axis=1)\n",
    "vsum1 = train_trn_f1[vcols].sum(axis=1)\n",
    "plt.scatter(train_trn_f0['_ymd'], vsum0, s=5)\n",
    "plt.scatter(train_trn_f1['_ymd'], vsum1, s=5, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_trn_f1[vcols].describe().T['max']\n",
    "m[m >= 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_trn_f0['_ymd'], train_trn_f0['V160'], s=5)\n",
    "plt.scatter(train_trn_f1['_ymd'], train_trn_f1['V160'], s=5, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcols_1 = [f'V{i}' for i in range(1,160)]+[f'V{i}' for i in range(161,340)]\n",
    "vsum0 = train_trn_f0[vcols_1].sum(axis=1)\n",
    "vsum1 = train_trn_f1[vcols_1].sum(axis=1)\n",
    "plt.scatter(train_trn_f0['_ymd'], vsum0, s=5)\n",
    "plt.scatter(train_trn_f1['_ymd'], vsum1, s=5, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[vcols].isnull().sum() / len(train_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn.loc[train_trn['V1'].isnull(), vcols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn.loc[train_trn['V1'].isnull() == False, vcols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "train_trn.loc[train_trn['isFraud']==0, vcols].isnull().sum(axis=1).to_frame().hist(ax=ax[0], bins=20)\n",
    "train_trn.loc[train_trn['isFraud']==1, vcols].isnull().sum(axis=1).to_frame().hist(ax=ax[1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trn[vcols].describe().T[['min','max']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcols = [f'V{i}' for i in range(1,340)]\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(train_trn[vcols].fillna(-1))\n",
    "plt.xlabel('components')\n",
    "plt.plot(np.add.accumulate(pca.explained_variance_ratio_))\n",
    "plt.show()\n",
    "\n",
    "pca = PCA(n_components=0.99)\n",
    "vcol_pca = pca.fit_transform(train_trn[vcols].fillna(-1))\n",
    "print(vcol_pca.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_trn_f0,train_trn_f1,train_id_f0,train_id_f1\n",
    "\n",
    "print(pd.DataFrame([[val for val in dir()], [sys.getsizeof(eval(val)) for val in dir()]],\n",
    "                   index=['name','size']).T.sort_values('size', ascending=False).reset_index(drop=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = pd.read_csv('../input/train_identity.csv')\n",
    "train_trn = pd.read_csv('../input/train_transaction.csv')\n",
    "test_id = pd.read_csv('../input/test_identity.csv')\n",
    "test_trn = pd.read_csv('../input/test_transaction.csv')\n",
    "\n",
    "id_cols = list(train_id.columns.values)\n",
    "trn_cols = list(train_trn.drop('isFraud', axis=1).columns.values)\n",
    "\n",
    "X_train = pd.merge(train_trn[trn_cols + ['isFraud']], train_id[id_cols], how='left')\n",
    "X_train = reduce_mem_usage(X_train)\n",
    "X_test = pd.merge(test_trn[trn_cols], test_id[id_cols], how='left')\n",
    "X_test = reduce_mem_usage(X_test)\n",
    "\n",
    "X_train_id = X_train.pop('TransactionID')\n",
    "X_test_id = X_test.pop('TransactionID')\n",
    "del train_id,train_trn,test_id,test_trn\n",
    "\n",
    "all_data = X_train.append(X_test, sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping vi features using PCA? TODO understand this\n",
    "#PCA Wikipedia- https://he.wikipedia.org/wiki/%D7%A0%D7%99%D7%AA%D7%95%D7%97_%D7%92%D7%95%D7%A8%D7%9E%D7%99%D7%9D_%D7%A8%D7%90%D7%A9%D7%99%D7%99%D7%9D\n",
    "\n",
    "vcols = [f'V{i}' for i in range(1,340)]\n",
    "sc = preprocessing.MinMaxScaler()\n",
    "\n",
    "pca = PCA(n_components=2) #0.99\n",
    "vcol_pca = pca.fit_transform(sc.fit_transform(all_data[vcols].fillna(-1)))\n",
    "\n",
    "all_data['_vcol_pca0'] = vcol_pca[:,0]\n",
    "all_data['_vcol_pca1'] = vcol_pca[:,1]\n",
    "all_data['_vcol_nulls'] = all_data[vcols].isnull().sum(axis=1)\n",
    "\n",
    "all_data.drop(vcols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date information Extraction! cool!\n",
    "\n",
    "import datetime\n",
    "\n",
    "START_DATE = '2017-12-01'\n",
    "startdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "all_data['Date'] = all_data['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n",
    "all_data['_weekday'] = all_data['Date'].dt.dayofweek\n",
    "all_data['_hour'] = all_data['Date'].dt.hour\n",
    "all_data['_day'] = all_data['Date'].dt.day\n",
    "\n",
    "all_data['_weekday'] = all_data['_weekday'].astype(str)\n",
    "all_data['_hour'] = all_data['_hour'].astype(str)\n",
    "all_data['_weekday__hour'] = all_data['_weekday'] + all_data['_hour']\n",
    "\n",
    "cnt_day = all_data['_day'].value_counts()\n",
    "cnt_day = cnt_day / cnt_day.mean()\n",
    "all_data['_count_rate'] = all_data['_day'].map(cnt_day.to_dict())\n",
    "\n",
    "all_data.drop(['TransactionDT','Date','_day'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO WHY?\n",
    "all_data['_P_emaildomain__addr1'] = all_data['P_emaildomain'] + '__' + all_data['addr1'].astype(str)\n",
    "all_data['_card1__card2'] = all_data['card1'].astype(str) + '__' + all_data['card2'].astype(str)\n",
    "all_data['_card1__addr1'] = all_data['card1'].astype(str) + '__' + all_data['addr1'].astype(str)\n",
    "all_data['_card2__addr1'] = all_data['card2'].astype(str) + '__' + all_data['addr1'].astype(str)\n",
    "all_data['_card12__addr1'] = all_data['_card1__card2'] + '__' + all_data['addr1'].astype(str)\n",
    "all_data['_card_all__addr1'] = all_data['_card1__card2'] + '__' + all_data['addr1'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['_amount_decimal'] = ((all_data['TransactionAmt'] - all_data['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "all_data['_amount_decimal_len'] = all_data['TransactionAmt'].apply(lambda x: len(re.sub('0+$', '', str(x)).split('.')[1]))\n",
    "all_data['_amount_fraction'] = all_data['TransactionAmt'].apply(lambda x: float('0.'+re.sub('^[0-9]|\\.|0+$', '', str(x))))\n",
    "all_data[['TransactionAmt','_amount_decimal','_amount_decimal_len','_amount_fraction']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics based on several features (how thery were chosen?? TODO)\n",
    "cols = ['ProductCD','card1','card2','card5','card6','P_emaildomain','_card_all__addr1']\n",
    "#,'card3','card4','addr1','dist2','R_emaildomain'\n",
    "\n",
    "# amount mean&std\n",
    "for f in cols:\n",
    "    all_data[f'_amount_mean_{f}'] = all_data['TransactionAmt'] / all_data.groupby([f])['TransactionAmt'].transform('mean')\n",
    "    all_data[f'_amount_std_{f}'] = all_data['TransactionAmt'] / all_data.groupby([f])['TransactionAmt'].transform('std')\n",
    "    all_data[f'_amount_pct_{f}'] = (all_data['TransactionAmt'] - all_data[f'_amount_mean_{f}']) / all_data[f'_amount_std_{f}']\n",
    "\n",
    "# freq encoding\n",
    "for f in cols:\n",
    "    vc = all_data[f].value_counts(dropna=False)\n",
    "    all_data[f'_count_{f}'] = all_data[f].map(vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('features:', all_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_='''\n",
    "cat_cols = ['ProductCD','card1','card2','card3','card4','card5','card6','addr1','addr2','P_emaildomain','R_emaildomain',\n",
    "            'M1','M2','M3','M4','M5','M6','M7','M8','M9','DeviceType','DeviceInfo'] + [f'id_{i}' for i in range(12,39)]\n",
    "'''\n",
    "cat_cols = [f'id_{i}' for i in range(12,39)]\n",
    "for i in cat_cols:\n",
    "    if i in all_data.columns:\n",
    "        all_data[i] = all_data[i].astype(str)\n",
    "        all_data[i].fillna('unknown', inplace=True)\n",
    "\n",
    "enc_cols = []\n",
    "for i, t in all_data.loc[:, all_data.columns != 'isFraud'].dtypes.iteritems():\n",
    "    if t == object:\n",
    "        enc_cols.append(i)\n",
    "        #df = pd.concat([df, pd.get_dummies(df[i].astype(str), prefix=i)], axis=1)\n",
    "        #df.drop(i, axis=1, inplace=True)\n",
    "        all_data[i] = pd.factorize(all_data[i])[0]\n",
    "        #all_data[i] = all_data[i].astype('category')\n",
    "print(enc_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = all_data[all_data['isFraud'].notnull()]\n",
    "X_test = all_data[all_data['isFraud'].isnull()].drop('isFraud', axis=1)\n",
    "Y_train = X_train.pop('isFraud')\n",
    "del all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "params={'learning_rate': 0.01,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'num_threads': -1,\n",
    "        'num_leaves': 256,\n",
    "        'verbose': 1,\n",
    "        'random_state': 42,\n",
    "        'bagging_fraction': 1,\n",
    "        'feature_fraction': 0.85\n",
    "       }\n",
    "\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "sub_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "clf = lgb.LGBMClassifier(**params, n_estimators=3000)\n",
    "clf.fit(X_train, Y_train)\n",
    "oof_preds = clf.predict_proba(X_train, num_iteration=clf.best_iteration_)[:,1]\n",
    "sub_preds = clf.predict_proba(X_test, num_iteration=clf.best_iteration_)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feature_importance = clf.feature_importances_\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "sorted_idx = sorted_idx[len(feature_importance) - 50:]\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "plt.figure(figsize=(10,12))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X_train.columns[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['TransactionID'] = X_test_id\n",
    "submission['isFraud'] = sub_preds\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
